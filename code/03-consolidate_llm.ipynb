{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fifth-deployment",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "from copy import deepcopy\n",
    "from collections     import Counter\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import Levenshtein as lev\n",
    "import numpy as np\n",
    "\n",
    "from pybtex.database import parse_string\n",
    "from pylatexenc.latex2text import LatexNodes2Text\n",
    "conv = LatexNodes2Text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "795e4c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rispy\n",
    "mappings = deepcopy(rispy.TAG_KEY_MAPPING)\n",
    "mappings['M2'] = 'extra'\n",
    "mappings['M3'] = 'orig_abstract'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fa9b837",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_isbn(input_string):\n",
    "    \"\"\"\n",
    "    Extract an ISBN from an unstructured text string.\n",
    "    \n",
    "    The function searches for ISBN numbers that may include a check character 'X' at the end.\n",
    "    It recognizes ISBNs both with and without spaces or hyphens between segments.\n",
    "    \"\"\"\n",
    "    # Regular expression to match \"ISBN:\" followed by any combination of digits, hyphens, and possibly ending with an 'X'\n",
    "    pattern = r'ISBN:?\\s*([\\d\\-]+X?)'\n",
    "    \n",
    "    match = re.search(pattern, input_string)\n",
    "    if match:\n",
    "        return match.group(1)  # Return the matched part (ISBN number)\n",
    "    else:\n",
    "        return None  # No ISBN found following the \"ISBN:\" prefix\n",
    "    \n",
    "import re\n",
    "\n",
    "def extract_issn(input_string):\n",
    "    \"\"\"\n",
    "    Extract an ISSN from an unstructured text string.\n",
    "    \n",
    "    The function searches for ISSN numbers, which are typically in the format '1234-5678'.\n",
    "    It recognizes ISSNs both with and without spaces or hyphens between segments.\n",
    "    \"\"\"\n",
    "    # Regular expression to match \"ISSN:\" followed by a valid ISSN format\n",
    "    pattern = r'ISSN:?\\s*(\\d{4}-\\d{3}[\\dX])'\n",
    "    \n",
    "    match = re.search(pattern, input_string)\n",
    "    if match:\n",
    "        return match.group(1)  # Return the matched part (ISSN number)\n",
    "    else:\n",
    "        return None  # No ISSN found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1c1f079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'978-0-19-880393-5'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_isbn(\"ISBN: 978-0-19-880393-5. P. VII-VIII Acknowledgements; p. XI-XII List of illustrations; p. XIII-XXIV Preface: what this book is (not) about; p. 1-21 Introduction: biblical philology in the sixteenth century; p. 253-280 Bibliography; p. 281-296 Index.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f435a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_chapter(ris, bibt):\n",
    "    # make editors authors, if applicable:\n",
    "    if 'editor' in bibt.persons:\n",
    "        if 'author' in bibt.persons:\n",
    "            ris['first_authors'] = [conv.latex_to_text(str(editor)) for editor in bibt.persons['author']]\n",
    "        else:\n",
    "            if 'authors' in ris:\n",
    "                del ris['authors']\n",
    "        ris['secondary_authors'] = [conv.latex_to_text(str(editor)) for editor in bibt.persons['editor']]\n",
    "\n",
    "    if 'first_authors' in ris and 'secondary_authors' in ris:\n",
    "        if 'authors' in ris:\n",
    "            del ris['authors']\n",
    "\n",
    "    # add translators\n",
    "    if 'translator' in bibt.fields:\n",
    "        ris['tertiary_authors'] = conv.latex_to_text(bibt.fields['translator']).split(' and ')\n",
    "\n",
    "    for f in bibt.fields:\n",
    "        bibt.fields[f] = conv.latex_to_text(bibt.fields[f])\n",
    "    \n",
    "    # replace non-distinct title with parsed journal title:\n",
    "    if 'title' in bibt.fields:\n",
    "        ris['extra'] = ris['title']\n",
    "        ris['title'] = bibt.fields['title']\n",
    "\n",
    "    if 'booktitle' in bibt.fields:\n",
    "        ris['secondary_title'] = bibt.fields['booktitle']\n",
    "    \n",
    "    if 'pagetotal' in bibt.fields:\n",
    "        ris['end_page'] = bibt.fields['pagetotal']\n",
    "    \n",
    "    if 'pages' in bibt.fields:\n",
    "        pages = bibt.fields['pages'].split('-')\n",
    "        if len(pages) == 2:\n",
    "            ris['start_page'] = pages[0]\n",
    "            ris['end_page'] = pages[1]\n",
    "        else:\n",
    "            ris['start_page'] = bibt.fields['pages']\n",
    "    \n",
    "    if 'publisher' in bibt.fields:\n",
    "        ris['publisher'] = bibt.fields['publisher']\n",
    "\n",
    "    if 'place' in bibt.fields:\n",
    "        ris['place_published'] = bibt.fields['place']\n",
    "\n",
    "    if 'address' in bibt.fields:\n",
    "        ris['place_published'] = bibt.fields['address']\n",
    "    \n",
    "    if 'location' in bibt.fields:\n",
    "        ris['place_published'] = bibt.fields['location']\n",
    "\n",
    "    if 'series' in bibt.fields:\n",
    "        ris['tertiary_title'] = bibt.fields['series']\n",
    "\n",
    "    if 'volume' in bibt.fields:\n",
    "        ris['volume'] = bibt.fields['volume']\n",
    "\n",
    "    if 'number' in bibt.fields:\n",
    "        ris['number'] = bibt.fields['number']\n",
    "\n",
    "    if 'edition' in bibt.fields:\n",
    "        ris['edition'] = bibt.fields['edition']\n",
    "    \n",
    "    return ris"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6c45da",
   "metadata": {},
   "source": [
    "Collect already available normalizations for journal titles (so that we can find out below which one we miss):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10036c79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>secondary_title</th>\n",
       "      <th>normalized</th>\n",
       "      <th>count</th>\n",
       "      <th>issn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ons erfdeel: kultureel tijdschrift voor Zuidvl...</td>\n",
       "      <td>Ons erfdeel</td>\n",
       "      <td>2660.0</td>\n",
       "      <td>0030-2651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dietsche warande en Belfort: tijdschrift voor ...</td>\n",
       "      <td>Dietsche warande en Belfort</td>\n",
       "      <td>2461.0</td>\n",
       "      <td>0012-2645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>De nieuwe taalgids: tweemaandelijks tijdschrif...</td>\n",
       "      <td>De nieuwe taalgids</td>\n",
       "      <td>2359.0</td>\n",
       "      <td>0028-9922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bzzlletin; Stichting BZZTôH Teater. Voorburg: ...</td>\n",
       "      <td>Bzzlletin</td>\n",
       "      <td>1638.0</td>\n",
       "      <td>0165-0858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Poëziekrant: tweemaandelijks tijdschrift. Gent...</td>\n",
       "      <td>Poëziekrant</td>\n",
       "      <td>1573.0</td>\n",
       "      <td>2030-0638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Onze taal: maandblad van het Genootschap Onze ...</td>\n",
       "      <td>Onze taal</td>\n",
       "      <td>1322.0</td>\n",
       "      <td>0165-7828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Vlaanderen: tweemaandelijks tijdschrift voor k...</td>\n",
       "      <td>Vlaanderen</td>\n",
       "      <td>1312.0</td>\n",
       "      <td>0042-7683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>De gids: nieuwe vaderlandsche letteroefeningen...</td>\n",
       "      <td>De gids</td>\n",
       "      <td>1249.0</td>\n",
       "      <td>0016-9730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Levende talen: berichten en mededelingen van d...</td>\n",
       "      <td>Levende talen</td>\n",
       "      <td>1239.0</td>\n",
       "      <td>0024-1539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tijdschrift voor Nederlandse taal- en letterku...</td>\n",
       "      <td>Tijdschrift voor Nederlandse taal- en letterkunde</td>\n",
       "      <td>962.0</td>\n",
       "      <td>0040-7550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Literatuur: tijdschrift over Nederlandse lette...</td>\n",
       "      <td>Literatuur</td>\n",
       "      <td>926.0</td>\n",
       "      <td>0168-7050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Leesidee: kritisch-bibliografisch tijdschrift;...</td>\n",
       "      <td>Leesidee</td>\n",
       "      <td>918.0</td>\n",
       "      <td>1370-1053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Maatstaf: maandblad voor letteren. 's-Gravenha...</td>\n",
       "      <td>Maatstaf</td>\n",
       "      <td>886.0</td>\n",
       "      <td>0024-8851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>De periscoop: spiegel van het literair en arti...</td>\n",
       "      <td>De periscoop</td>\n",
       "      <td>853.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Het boek van nu: maandblad voor boekenvrienden...</td>\n",
       "      <td>Het boek van nu</td>\n",
       "      <td>813.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Kreatief: driemaandelijks literair- en kunstkr...</td>\n",
       "      <td>Kreatief</td>\n",
       "      <td>808.0</td>\n",
       "      <td>0772-6376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Critisch bulletin: maandblad voor letterkundig...</td>\n",
       "      <td>Critisch bulletin</td>\n",
       "      <td>773.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Biekorf: dat is een leer- en leesblad voor all...</td>\n",
       "      <td>Biekorf</td>\n",
       "      <td>762.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Kruispunt: driemaandelijks tijdschrift. Brugge...</td>\n",
       "      <td>Kruispunt</td>\n",
       "      <td>745.0</td>\n",
       "      <td>0774-7233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Neerlandia: orgaan van het Algemeen Nederlands...</td>\n",
       "      <td>Neerlandia</td>\n",
       "      <td>729.0</td>\n",
       "      <td>0028-2383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Tirade. Amsterdam: Van Oorschot, 1957-....</td>\n",
       "      <td>Tirade</td>\n",
       "      <td>705.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>De Vlaamsche gids: algemeen tweemaandelijksch ...</td>\n",
       "      <td>De Vlaamsche gids</td>\n",
       "      <td>685.0</td>\n",
       "      <td>0042-7675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Septentrion: revue de culture néerlandaise. Re...</td>\n",
       "      <td>Septentrion</td>\n",
       "      <td>675.0</td>\n",
       "      <td>0771-8934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Ontmoeting: letterkundig en algemeen-cultureel...</td>\n",
       "      <td>Ontmoeting</td>\n",
       "      <td>650.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Spiegel der letteren: tijdschrift voor Nederla...</td>\n",
       "      <td>Spiegel der letteren</td>\n",
       "      <td>643.0</td>\n",
       "      <td>0038-7479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Spektator: tijdschrift voor Neerlandistiek. Gr...</td>\n",
       "      <td>Spektator</td>\n",
       "      <td>631.0</td>\n",
       "      <td>0165-084X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Dooijes, Dick. Boektypografische verkenningen:...</td>\n",
       "      <td>Dooijes, Dick</td>\n",
       "      <td>603.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Yang: tijdschrift voor literatuur en kommunika...</td>\n",
       "      <td>Yang</td>\n",
       "      <td>602.0</td>\n",
       "      <td>0775-2830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Taal en tongval: tijdschrift voor de studie va...</td>\n",
       "      <td>Taal en tongval</td>\n",
       "      <td>561.0</td>\n",
       "      <td>0039-8691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Verslagen en mededelingen van de Koninklijke A...</td>\n",
       "      <td>Verslagen en mededelingen van de Koninklijke A...</td>\n",
       "      <td>559.0</td>\n",
       "      <td>0770-786X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      secondary_title  \\\n",
       "0   Ons erfdeel: kultureel tijdschrift voor Zuidvl...   \n",
       "1   Dietsche warande en Belfort: tijdschrift voor ...   \n",
       "2   De nieuwe taalgids: tweemaandelijks tijdschrif...   \n",
       "3   Bzzlletin; Stichting BZZTôH Teater. Voorburg: ...   \n",
       "4   Poëziekrant: tweemaandelijks tijdschrift. Gent...   \n",
       "5   Onze taal: maandblad van het Genootschap Onze ...   \n",
       "6   Vlaanderen: tweemaandelijks tijdschrift voor k...   \n",
       "7   De gids: nieuwe vaderlandsche letteroefeningen...   \n",
       "8   Levende talen: berichten en mededelingen van d...   \n",
       "9   Tijdschrift voor Nederlandse taal- en letterku...   \n",
       "10  Literatuur: tijdschrift over Nederlandse lette...   \n",
       "11  Leesidee: kritisch-bibliografisch tijdschrift;...   \n",
       "12  Maatstaf: maandblad voor letteren. 's-Gravenha...   \n",
       "13  De periscoop: spiegel van het literair en arti...   \n",
       "14  Het boek van nu: maandblad voor boekenvrienden...   \n",
       "15  Kreatief: driemaandelijks literair- en kunstkr...   \n",
       "16  Critisch bulletin: maandblad voor letterkundig...   \n",
       "17  Biekorf: dat is een leer- en leesblad voor all...   \n",
       "18  Kruispunt: driemaandelijks tijdschrift. Brugge...   \n",
       "19  Neerlandia: orgaan van het Algemeen Nederlands...   \n",
       "20         Tirade. Amsterdam: Van Oorschot, 1957-....   \n",
       "21  De Vlaamsche gids: algemeen tweemaandelijksch ...   \n",
       "22  Septentrion: revue de culture néerlandaise. Re...   \n",
       "23  Ontmoeting: letterkundig en algemeen-cultureel...   \n",
       "24  Spiegel der letteren: tijdschrift voor Nederla...   \n",
       "25  Spektator: tijdschrift voor Neerlandistiek. Gr...   \n",
       "26  Dooijes, Dick. Boektypografische verkenningen:...   \n",
       "27  Yang: tijdschrift voor literatuur en kommunika...   \n",
       "28  Taal en tongval: tijdschrift voor de studie va...   \n",
       "29  Verslagen en mededelingen van de Koninklijke A...   \n",
       "\n",
       "                                           normalized   count       issn  \n",
       "0                                         Ons erfdeel  2660.0  0030-2651  \n",
       "1                         Dietsche warande en Belfort  2461.0  0012-2645  \n",
       "2                                  De nieuwe taalgids  2359.0  0028-9922  \n",
       "3                                           Bzzlletin  1638.0  0165-0858  \n",
       "4                                         Poëziekrant  1573.0  2030-0638  \n",
       "5                                           Onze taal  1322.0  0165-7828  \n",
       "6                                          Vlaanderen  1312.0  0042-7683  \n",
       "7                                             De gids  1249.0  0016-9730  \n",
       "8                                       Levende talen  1239.0  0024-1539  \n",
       "9   Tijdschrift voor Nederlandse taal- en letterkunde   962.0  0040-7550  \n",
       "10                                         Literatuur   926.0  0168-7050  \n",
       "11                                           Leesidee   918.0  1370-1053  \n",
       "12                                           Maatstaf   886.0  0024-8851  \n",
       "13                                       De periscoop   853.0        NaN  \n",
       "14                                    Het boek van nu   813.0        NaN  \n",
       "15                                           Kreatief   808.0  0772-6376  \n",
       "16                                  Critisch bulletin   773.0        NaN  \n",
       "17                                            Biekorf   762.0        NaN  \n",
       "18                                          Kruispunt   745.0  0774-7233  \n",
       "19                                         Neerlandia   729.0  0028-2383  \n",
       "20                                             Tirade   705.0        NaN  \n",
       "21                                  De Vlaamsche gids   685.0  0042-7675  \n",
       "22                                        Septentrion   675.0  0771-8934  \n",
       "23                                         Ontmoeting   650.0        NaN  \n",
       "24                               Spiegel der letteren   643.0  0038-7479  \n",
       "25                                          Spektator   631.0  0165-084X  \n",
       "26                                      Dooijes, Dick   603.0        NaN  \n",
       "27                                               Yang   602.0  0775-2830  \n",
       "28                                    Taal en tongval   561.0  0039-8691  \n",
       "29  Verslagen en mededelingen van de Koninklijke A...   559.0  0770-786X  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jtitle = pd.read_excel('../data/journal_titles_master.xlsx')\n",
    "existing_jtitles = set(jtitle['normalized'])\n",
    "lower2jtitles = dict(zip(jtitle['normalized'].str.lower(), jtitle['normalized']))\n",
    "jtitle.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb85e467",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_journal(ris, bibt):\n",
    "    \"\"\"\n",
    "    Merges the newly structured information in the bibtex returned\n",
    "    by the LLM into the already available RIS entry from the dump.\n",
    "    Reliably structured information (e.g. authors, year, keywords, ...)\n",
    "    from the RIS entries is maximally retained.\n",
    "    \"\"\"\n",
    "    #print(ris)\n",
    "    #print(bibt)\n",
    "    #print('===============================================')\n",
    "\n",
    "    for f in bibt.fields:\n",
    "        bibt.fields[f] = conv.latex_to_text(bibt.fields[f])\n",
    "    \n",
    "    # replace unstructured title with parsed journal title (if available):\n",
    "    if 'title' in bibt.fields:\n",
    "        # keep track of original title description:\n",
    "        ris['extra'] = [ris['title']]\n",
    "        ris['title'] = bibt.fields['title']\n",
    "        if ris['title'].endswith(','):\n",
    "            ris['title'] = ris['title'][:-1]\n",
    "        if ris['title'].strip().lower() in ('in', 'untitled', 'title of the article', 'title of the article (if provided)'):\n",
    "            ris['title'] = ''\n",
    "    \n",
    "    # parse pagination information:\n",
    "    if 'pagetotal' in bibt.fields:\n",
    "        ris['end_page'] = bibt.fields['pagetotal']\n",
    "    if 'pages' in bibt.fields:\n",
    "        pages = bibt.fields['pages'].split('-')\n",
    "        if len(pages) == 2:\n",
    "            ris['start_page'] = pages[0]\n",
    "            ris['end_page'] = pages[1]\n",
    "        else:\n",
    "            ris['end_page'] = bibt.fields['pages']\n",
    "\n",
    "    # collect parsed journal title (unless we had that information already, which will be more reliable)\n",
    "    if 'secondary_title' not in ris and 'journal' in bibt.fields:\n",
    "        journal = bibt.fields['journal']\n",
    "        # sometimes place of publication of the journal is added: we remove that\n",
    "        journal = journal.split('(')[0].strip()\n",
    "        journal = journal.split('[')[0].strip()\n",
    "        ris['journal_name'] = journal\n",
    "    elif 'secondary_title' in ris and 'journal' in bibt.fields:\n",
    "        ris['journal_name'] = ris['secondary_title']\n",
    "        del ris['secondary_title']\n",
    "\n",
    "    if 'journal_name' in ris:\n",
    "        jn = ris['journal_name']\n",
    "        if jn.startswith('\"') and jn.endswith('\",'):\n",
    "            jn = jn[1:-2]\n",
    "        if jn.count('\"') == 1:\n",
    "            jn = jn.replace('\"', '')\n",
    "        ris['journal_name'] = jn\n",
    "    \n",
    "    # collect information on volume and issue\n",
    "    if 'volume' in bibt.fields:\n",
    "        ris['volume'] = bibt.fields['volume']\n",
    "    if 'number' in bibt.fields:\n",
    "        ris['number'] = bibt.fields['number']\n",
    "    if 'number' not in bibt.fields and 'issue' in bibt.fields:\n",
    "        ris['number'] = bibt.fields['issue']\n",
    "    \n",
    "    if 'volume' in ris and not 'number' in ris:\n",
    "        ris['number'] = ris['volume']\n",
    "        del ris['volume']\n",
    "    \n",
    "    return ris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "daec9dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_book(ris, bibt):\n",
    "    # extract ISBN for abstract field, if available:\n",
    "    if 'orig_abstract' in ris:\n",
    "        abstract = ris['orig_abstract']\n",
    "        isbn = extract_isbn(abstract.strip())\n",
    "        if isbn:\n",
    "            ris['issn'] = isbn\n",
    "\n",
    "    # make editors authors, if applicable:\n",
    "    if 'editor' in bibt.persons:\n",
    "        if 'author' in bibt.persons:\n",
    "            ris['first_authors'] = [conv.latex_to_text(str(editor)) for editor in bibt.persons['author']]\n",
    "        else:\n",
    "            if 'author' in ris:\n",
    "                del ris['author']\n",
    "            if 'authors' in ris:\n",
    "                del ris['authors']\n",
    "        ris['secondary_authors'] = [conv.latex_to_text(str(editor)) for editor in bibt.persons['editor']]\n",
    "\n",
    "    if 'first_authors' in ris and 'secondary_authors' in ris:\n",
    "        if 'author' in ris:\n",
    "            del ris['author']\n",
    "        if 'authors' in ris:\n",
    "            del ris['authors']\n",
    "\n",
    "    # add translators\n",
    "    if 'translator' in bibt.fields:\n",
    "        ris['tertiary_authors'] = conv.latex_to_text(bibt.fields['translator']).split(' and ')\n",
    "        if 'author' in ris:\n",
    "            del ris['author']\n",
    "        if 'first_authors' in ris:\n",
    "            del ris['first_authors']\n",
    "\n",
    "    for f in bibt.fields:\n",
    "        bibt.fields[f] = conv.latex_to_text(bibt.fields[f])\n",
    "    \n",
    "    # replace non-distinct title with parsed book title:\n",
    "    if 'title' in bibt.fields and bibt.fields['title']:\n",
    "        try:\n",
    "            ris['extra'].append(ris['title'])\n",
    "        except KeyError:\n",
    "            ris['extra'] = [ris['title']]\n",
    "        ris['title'] = bibt.fields['title']\n",
    "    elif 'booktitle' in bibt.fields and bibt.fields['booktitle']:\n",
    "        try:\n",
    "            ris['extra'].append(ris['title'])\n",
    "        except KeyError:\n",
    "            ris['extra'] = [ris['title']]\n",
    "        ris['title'] = bibt.fields['booktitle']\n",
    "    \n",
    "    if 'pagetotal' in bibt.fields:\n",
    "        ris['start_page'] = bibt.fields['pagetotal']\n",
    "    \n",
    "    if 'pages' in bibt.fields:\n",
    "        ris['start_page'] = bibt.fields['pages']\n",
    "    \n",
    "    if 'publisher' in bibt.fields:\n",
    "        ris['publisher'] = bibt.fields['publisher']\n",
    "\n",
    "    if 'place' in bibt.fields:\n",
    "        ris['place_published'] = bibt.fields['place']\n",
    "\n",
    "    if 'place' in bibt.fields:\n",
    "        place = bibt.fields['place']\n",
    "        if ris['extra'] and '[' + place + ']' in ris['extra'][0]:\n",
    "            place = '[' + place + ']'\n",
    "        ris['place_published'] = place\n",
    "\n",
    "    if 'address' in bibt.fields:\n",
    "        ris['place_published'] = bibt.fields['address']\n",
    "    \n",
    "    if 'location' in bibt.fields:\n",
    "        ris['place_published'] = bibt.fields['location']\n",
    "\n",
    "    if 'series' in bibt.fields:\n",
    "        if ';' in bibt.fields['series']:\n",
    "            series, vol = [e.strip() for e in bibt.fields['series'].split(';', maxsplit=1)]\n",
    "            ris['secondary_title'] = series\n",
    "            ris['note'] = vol\n",
    "        else:\n",
    "            ris['secondary_title'] = bibt.fields['series']\n",
    "\n",
    "    if 'volume' in bibt.fields:\n",
    "        ris['note'] = bibt.fields['volume']\n",
    "\n",
    "    if 'number' in bibt.fields:\n",
    "        ris['note'] = bibt.fields['number']\n",
    "\n",
    "    if 'edition' in bibt.fields:\n",
    "        ris['edition'] = bibt.fields['edition']\n",
    "    \n",
    "    return ris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72dd0f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_jfull(ris, bibt):\n",
    "    for f in bibt.fields:\n",
    "        bibt.fields[f] = conv.latex_to_text(bibt.fields[f])\n",
    "    \n",
    "    # extract ISSN from title field, if available:\n",
    "    if 'title' in ris:\n",
    "        abstract = ris['title']\n",
    "        issn = extract_issn(abstract.strip())\n",
    "        if issn:\n",
    "            ris['issn'] = issn\n",
    "    \n",
    "    # replace non-distinct title with parsed book title:\n",
    "    if 'title' in bibt.fields and bibt.fields['title']:\n",
    "        ris['extra'] = [ris['title']]\n",
    "        ris['title'] = bibt.fields['title']\n",
    "    elif 'booktitle' in bibt.fields and bibt.fields['booktitle']:\n",
    "        ris['extra'] = ris['title']\n",
    "        ris['title'] = bibt.fields['booktitle']\n",
    "\n",
    "    if 'first_authors' in ris:\n",
    "        ris['secondary_authors'] = ris['first_authors']\n",
    "        del ris['first_authors']\n",
    "    \n",
    "    if 'authors' in ris:\n",
    "        ris['secondary_authors'] = ris['authors']\n",
    "        del ris['authors']\n",
    "    \n",
    "    for f in bibt.fields:\n",
    "        bibt.fields[f] = conv.latex_to_text(bibt.fields[f])\n",
    "    \n",
    "    # pagination information:\n",
    "    if 'pagetotal' in bibt.fields:\n",
    "        ris['start_page'] = bibt.fields['pagetotal']\n",
    "    if 'pages' in bibt.fields:\n",
    "        ris['start_page'] = bibt.fields['pages']\n",
    "    \n",
    "    # publisher information:\n",
    "    if 'publisher' in bibt.fields:\n",
    "        ris['publisher'] = bibt.fields['publisher']\n",
    "\n",
    "    # place of publication:\n",
    "    if 'place' in bibt.fields:\n",
    "        ris['place_published'] = bibt.fields['place']\n",
    "    if 'place' in bibt.fields:\n",
    "        place = bibt.fields['place']\n",
    "        if ris['extra'] and '[' + place + ']' in ris['extra'][0]:\n",
    "            place = '[' + place + ']'\n",
    "        ris['place_published'] = place\n",
    "    if 'address' in bibt.fields:\n",
    "        ris['place_published'] = bibt.fields['address']\n",
    "    if 'location' in bibt.fields:\n",
    "        ris['place_published'] = bibt.fields['location']\n",
    "\n",
    "    if 'volume' in bibt.fields:\n",
    "        ris['volume'] = bibt.fields['volume']\n",
    "\n",
    "    if 'number' in bibt.fields:\n",
    "        ris['number'] = bibt.fields['number']\n",
    "\n",
    "    # Reset to BOOK\n",
    "    ris['type_of_reference'] = 'BOOK'\n",
    "    if 'keywords' in ris:\n",
    "        ris['keywords'].append('Speciaal tijdschriftnummer')\n",
    "    ris['keywords'] = tuple(set(ris['keywords']))\n",
    "    \n",
    "    return ris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2236510",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_entry = {\n",
    "             'JOUR': map_journal,\n",
    "             'CHAP': map_chapter,\n",
    "             'BOOK': map_book,\n",
    "             'JFULL': map_jfull,\n",
    "             'EJOUR': map_journal,\n",
    "             'ADVS': map_book,\n",
    "             'WEB': map_book,\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bcd701a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:87: SyntaxWarning: invalid escape sequence '\\&'\n",
      "<>:87: SyntaxWarning: invalid escape sequence '\\&'\n",
      "/var/folders/6j/pn9nz6b55j3fpdt8gtj50crm0000gn/T/ipykernel_49088/2234798805.py:87: SyntaxWarning: invalid escape sequence '\\&'\n",
      "  line = line.replace(' &', ' \\&')\n"
     ]
    }
   ],
   "source": [
    "def deduplicate_bibtex(bibt):\n",
    "    \"\"\"\n",
    "    Deduplicate repeated fields in the bibtex returned by the LLM.\n",
    "    We only keep the first appearance of a given field.\n",
    "    \"\"\"\n",
    "    lines, fields = [], set()\n",
    "    for line in bibt.strip().split('\\n'):\n",
    "        if line.startswith('@') or line == '}':\n",
    "            lines.append(line)\n",
    "        else:\n",
    "            field = line.split('=')[0].strip()\n",
    "            if field not in fields:\n",
    "                lines.append(line)\n",
    "                fields.add(field)\n",
    "\n",
    "    clean = '\\n'.join([l for l in lines if l])\n",
    "    if not clean.strip().endswith('}'):\n",
    "        clean += '\\n}\\n'\n",
    "    \n",
    "    return clean\n",
    "\n",
    "\n",
    "def clean_bibtex(bibt):\n",
    "    \"\"\"\n",
    "    Attempts to correct some common syntactic errors in the bibtex\n",
    "    returned by the LLM (which cause the pybtex parser to fail).\n",
    "    \"\"\"\n",
    "    if not bibt:\n",
    "        return ''\n",
    "    \n",
    "    # remove erroneous markdown syntax:\n",
    "    bibt = bibt.replace('```bibtex', '').replace('```', '').replace(\"```tex\", '')\n",
    "    \n",
    "    # sometimes mutliple bibtexs are created: we only keep the first one\n",
    "    bibt = [b for b in bibt.split('@') if b.strip()]\n",
    "    bibt = '@' + bibt[0]\n",
    "\n",
    "    lines = []\n",
    "    for line in bibt.strip().split('\\n'):\n",
    "        l = line.strip()\n",
    "\n",
    "        # take care of spaces in the bibtex key:\n",
    "        if l.startswith('@') and ' ' in l:\n",
    "            line = ''.join(line.split())\n",
    "        \n",
    "        # fix missing entry keys:\n",
    "        if l in ('@article{,', '@article{'):\n",
    "            lines.append('@article{xxx,')\n",
    "            continue\n",
    "        if l in ('@book{,', '@book{'):\n",
    "            lines.append('@book{xxx,')\n",
    "            continue\n",
    "        if l in ('@incollection{,', '@incollection{'):\n",
    "            lines.append('@incollection{xxx,')\n",
    "            continue\n",
    "\n",
    "        # common errors:\n",
    "        if l.endswith(']'):\n",
    "            line += '},'\n",
    "            lines.append(line)\n",
    "            continue\n",
    "        line = line.replace('{ )', '{}')\n",
    "        if l.endswith(\"',\"):\n",
    "            line = line[:-2] + '},'\n",
    "        \n",
    "        # ensure that end-of-line syntax is respected:\n",
    "        if l != '}':\n",
    "            if not l.endswith('},'):\n",
    "                if l.endswith('}'):\n",
    "                    line += ','\n",
    "                elif not l.endswith('}') and not l.endswith(','):\n",
    "                    line += '},'\n",
    "            if l.endswith('),'):\n",
    "                line = line.replace('),', ')},')\n",
    "        \n",
    "        # add missing curly brackets:\n",
    "        if '=' in l and (not '{' in l or not '}' in l):\n",
    "            k, v = [e.strip() for e in l.split('=')][:2]\n",
    "            v.replace(',', '')\n",
    "            line = '  ' + k + '=' + '{' + v + '},'\n",
    "        \n",
    "        # remove lines with empty values:\n",
    "        if '= {},' in l:\n",
    "            continue\n",
    "\n",
    "        if ' &' in line:\n",
    "            line = line.replace(' &', ' \\&')\n",
    "        \n",
    "        # correct curly bracket syntax in title field:\n",
    "        if l.startswith('title') and l.count('}') > 1:\n",
    "            k, v = [e.strip() for e in l.split('=')][:2]\n",
    "            v = v.replace('{', '').replace('}', '')\n",
    "            line = '  ' + k + '=' + '{' + v + '},'\n",
    "\n",
    "        # correct syntax:\n",
    "        if '\",' in l and '=' in l:\n",
    "            k, v = [e.strip() for e in l.split('=')][:2]\n",
    "            if v.startswith('\"') and v.endswith('\",'):\n",
    "                v = v[1:-2]\n",
    "            line = '  ' + k + '=' + '{' + v + '},'\n",
    "\n",
    "        lines.append(line)\n",
    "\n",
    "    # recompose the lines of the bibtex entry:\n",
    "    clean = '\\n'.join([l for l in lines if l])\n",
    "    if not clean.strip().endswith('}'):\n",
    "        clean += '\\n}\\n'\n",
    "    \n",
    "    # return the deduplicated version of the bibtex entry:\n",
    "    return deduplicate_bibtex(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "739c482c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "::: ../data/llm-dump/1940s :::\n",
      "     -  ../data/llm-dump/1940s/BOOK.xlsx (BOOK)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1442/1442 [00:01<00:00, 1368.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status\n",
      "success    1418\n",
      "failure      24\n",
      "Name: count, dtype: int64\n",
      "     -  ../data/llm-dump/1940s/CHAP.xlsx (CHAP)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1764/1764 [00:01<00:00, 1078.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status\n",
      "success    1762\n",
      "failure       2\n",
      "Name: count, dtype: int64\n",
      "     -  ../data/llm-dump/1940s/JFULL.xlsx (JFULL)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:00<00:00, 656.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status\n",
      "success    56\n",
      "failure    12\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     -  ../data/llm-dump/1940s/JOUR.xlsx (JOUR)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9897/9897 [00:06<00:00, 1470.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status\n",
      "success    9888\n",
      "failure       9\n",
      "Name: count, dtype: int64\n",
      "::: ../data/llm-dump/1950s :::\n",
      "     -  ../data/llm-dump/1950s/BOOK.xlsx (BOOK)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 917/917 [00:00<00:00, 1188.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status\n",
      "success    916\n",
      "failure      1\n",
      "Name: count, dtype: int64\n",
      "     -  ../data/llm-dump/1950s/CHAP.xlsx (CHAP)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1161/1161 [00:00<00:00, 1178.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status\n",
      "success    1161\n",
      "Name: count, dtype: int64\n",
      "     -  ../data/llm-dump/1950s/JFULL.xlsx (JFULL)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:00<00:00, 350.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status\n",
      "success    16\n",
      "failure     1\n",
      "Name: count, dtype: int64\n",
      "     -  ../data/llm-dump/1950s/JOUR.xlsx (JOUR)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6218/6218 [00:04<00:00, 1500.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status\n",
      "success    6217\n",
      "failure       1\n",
      "Name: count, dtype: int64\n",
      "::: ../data/llm-dump/1960s :::\n",
      "     -  ../data/llm-dump/1960s/BOOK.xlsx (BOOK)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2185/2185 [00:02<00:00, 1082.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status\n",
      "success    2181\n",
      "failure       4\n",
      "Name: count, dtype: int64\n",
      "     -  ../data/llm-dump/1960s/CHAP.xlsx (CHAP)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4084/4084 [00:03<00:00, 1088.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status\n",
      "success    4084\n",
      "Name: count, dtype: int64\n",
      "     -  ../data/llm-dump/1960s/JFULL.xlsx (JFULL)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 190/190 [00:00<00:00, 747.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status\n",
      "success    174\n",
      "failure     16\n",
      "Name: count, dtype: int64\n",
      "     -  ../data/llm-dump/1960s/JOUR.xlsx (JOUR)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19387/19387 [00:13<00:00, 1474.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status\n",
      "success    19373\n",
      "failure       14\n",
      "Name: count, dtype: int64\n",
      "::: ../data/llm-dump/1970s :::\n",
      "     -  ../data/llm-dump/1970s/BOOK.xlsx (BOOK)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3623/3623 [00:02<00:00, 1248.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status\n",
      "success    3619\n",
      "failure       4\n",
      "Name: count, dtype: int64\n",
      "     -  ../data/llm-dump/1970s/CHAP.xlsx (CHAP)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6650/6650 [00:06<00:00, 1053.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status\n",
      "success    6645\n",
      "failure       5\n",
      "Name: count, dtype: int64\n",
      "     -  ../data/llm-dump/1970s/JFULL.xlsx (JFULL)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 273/273 [00:00<00:00, 702.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status\n",
      "success    258\n",
      "failure     15\n",
      "Name: count, dtype: int64\n",
      "     -  ../data/llm-dump/1970s/JOUR.xlsx (JOUR)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25511/25511 [00:17<00:00, 1463.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status\n",
      "success    25493\n",
      "failure       18\n",
      "Name: count, dtype: int64\n",
      "::: ../data/llm-dump/1980s :::\n",
      "     -  ../data/llm-dump/1980s/ADVS.xlsx (ADVS)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 1195.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status\n",
      "success    2\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     -  ../data/llm-dump/1980s/BOOK.xlsx (BOOK)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6722/6722 [00:05<00:00, 1191.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status\n",
      "success    6718\n",
      "failure       4\n",
      "Name: count, dtype: int64\n",
      "     -  ../data/llm-dump/1980s/CHAP.xlsx (CHAP)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12289/12289 [00:12<00:00, 958.12it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status\n",
      "success    12277\n",
      "failure       12\n",
      "Name: count, dtype: int64\n",
      "     -  ../data/llm-dump/1980s/JFULL.xlsx (JFULL)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 619/619 [00:00<00:00, 680.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status\n",
      "success    592\n",
      "failure     27\n",
      "Name: count, dtype: int64\n",
      "     -  ../data/llm-dump/1980s/JOUR.xlsx (JOUR)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34995/34995 [00:24<00:00, 1441.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status\n",
      "success    34977\n",
      "failure       18\n",
      "Name: count, dtype: int64\n",
      "     -  ../data/llm-dump/1980s/WEB.xlsx (WEB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 784.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status\n",
      "success    1\n",
      "Name: count, dtype: int64\n",
      "::: ../data/llm-dump/1990s :::\n",
      "     -  ../data/llm-dump/1990s/ADVS.xlsx (ADVS)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:00<00:00, 917.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status\n",
      "success    33\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     -  ../data/llm-dump/1990s/BOOK.xlsx (BOOK)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7992/7992 [00:06<00:00, 1167.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status\n",
      "success    7986\n",
      "failure       6\n",
      "Name: count, dtype: int64\n",
      "     -  ../data/llm-dump/1990s/CHAP.xlsx (CHAP)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14247/14247 [00:16<00:00, 879.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status\n",
      "success    14237\n",
      "failure       10\n",
      "Name: count, dtype: int64\n",
      "     -  ../data/llm-dump/1990s/EJOUR.xlsx (EJOUR)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [00:00<00:00, 885.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status\n",
      "success    96\n",
      "failure     1\n",
      "Name: count, dtype: int64\n",
      "     -  ../data/llm-dump/1990s/JFULL.xlsx (JFULL)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 660/660 [00:01<00:00, 616.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status\n",
      "success    636\n",
      "failure     24\n",
      "Name: count, dtype: int64\n",
      "     -  ../data/llm-dump/1990s/JOUR.xlsx (JOUR)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44498/44498 [00:31<00:00, 1433.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status\n",
      "success    44473\n",
      "failure       25\n",
      "Name: count, dtype: int64\n",
      "     -  ../data/llm-dump/1990s/WEB.xlsx (WEB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 1243.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status\n",
      "success    10\n",
      "Name: count, dtype: int64\n",
      "::: ../data/llm-dump/2000s :::\n",
      "     -  ../data/llm-dump/2000s/ADVS.xlsx (ADVS)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:00<00:00, 1051.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status\n",
      "success    54\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     -  ../data/llm-dump/2000s/BOOK.xlsx (BOOK)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6229/6229 [00:05<00:00, 1224.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status\n",
      "success    6220\n",
      "failure       9\n",
      "Name: count, dtype: int64\n",
      "     -  ../data/llm-dump/2000s/CHAP.xlsx (CHAP)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11027/11027 [00:12<00:00, 850.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status\n",
      "success    11021\n",
      "failure        6\n",
      "Name: count, dtype: int64\n",
      "     -  ../data/llm-dump/2000s/EJOUR.xlsx (EJOUR)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 628/628 [00:00<00:00, 1441.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status\n",
      "success    628\n",
      "Name: count, dtype: int64\n",
      "     -  ../data/llm-dump/2000s/JFULL.xlsx (JFULL)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 479/479 [00:00<00:00, 661.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status\n",
      "success    461\n",
      "failure     18\n",
      "Name: count, dtype: int64\n",
      "     -  ../data/llm-dump/2000s/JOUR.xlsx (JOUR)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27745/27745 [00:19<00:00, 1392.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status\n",
      "success    27735\n",
      "failure       10\n",
      "Name: count, dtype: int64\n",
      "     -  ../data/llm-dump/2000s/WEB.xlsx (WEB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 485/485 [00:00<00:00, 1506.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status\n",
      "success    483\n",
      "failure      2\n",
      "Name: count, dtype: int64\n",
      "::: ../data/llm-dump/2010s :::\n",
      "     -  ../data/llm-dump/2010s/ADVS.xlsx (ADVS)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 1125.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status\n",
      "success    9\n",
      "Name: count, dtype: int64\n",
      "     -  ../data/llm-dump/2010s/BOOK.xlsx (BOOK)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3891/3891 [00:02<00:00, 1299.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status\n",
      "success    3883\n",
      "failure       8\n",
      "Name: count, dtype: int64\n",
      "     -  ../data/llm-dump/2010s/CHAP.xlsx (CHAP)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6300/6300 [00:07<00:00, 809.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status\n",
      "success    6288\n",
      "failure      12\n",
      "Name: count, dtype: int64\n",
      "     -  ../data/llm-dump/2010s/EJOUR.xlsx (EJOUR)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 569/569 [00:00<00:00, 1516.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status\n",
      "success    568\n",
      "failure      1\n",
      "Name: count, dtype: int64\n",
      "     -  ../data/llm-dump/2010s/JFULL.xlsx (JFULL)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 442/442 [00:00<00:00, 687.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status\n",
      "success    416\n",
      "failure     26\n",
      "Name: count, dtype: int64\n",
      "     -  ../data/llm-dump/2010s/JOUR.xlsx (JOUR)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20043/20043 [00:14<00:00, 1352.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status\n",
      "success    20030\n",
      "failure       13\n",
      "Name: count, dtype: int64\n",
      "     -  ../data/llm-dump/2010s/WEB.xlsx (WEB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 85/85 [00:00<00:00, 735.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status\n",
      "success    85\n",
      "Name: count, dtype: int64\n",
      "::: ../data/llm-dump/2020s :::\n",
      "     -  ../data/llm-dump/2020s/ADVS.xlsx (ADVS)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 2205.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status\n",
      "success    1\n",
      "failure    1\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     -  ../data/llm-dump/2020s/BOOK.xlsx (BOOK)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 825/825 [00:00<00:00, 1363.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status\n",
      "success    824\n",
      "failure      1\n",
      "Name: count, dtype: int64\n",
      "     -  ../data/llm-dump/2020s/CHAP.xlsx (CHAP)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1627/1627 [00:01<00:00, 880.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status\n",
      "success    1627\n",
      "Name: count, dtype: int64\n",
      "     -  ../data/llm-dump/2020s/EJOUR.xlsx (EJOUR)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251/251 [00:00<00:00, 1493.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status\n",
      "success    251\n",
      "Name: count, dtype: int64\n",
      "     -  ../data/llm-dump/2020s/JFULL.xlsx (JFULL)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 161/161 [00:00<00:00, 706.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status\n",
      "success    150\n",
      "failure     11\n",
      "Name: count, dtype: int64\n",
      "     -  ../data/llm-dump/2020s/JOUR.xlsx (JOUR)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5238/5238 [00:03<00:00, 1373.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status\n",
      "success    5237\n",
      "failure       1\n",
      "Name: count, dtype: int64\n",
      "     -  ../data/llm-dump/2020s/WEB.xlsx (WEB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1290.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status\n",
      "success    1\n",
      "Name: count, dtype: int64\n",
      "::: ../data/llm-dump/misc :::\n",
      "     -  ../data/llm-dump/misc/ADVS.xlsx (ADVS)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 846.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status\n",
      "success    3\n",
      "Name: count, dtype: int64\n",
      "     -  ../data/llm-dump/misc/BOOK.xlsx (BOOK)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1182/1182 [00:00<00:00, 1345.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status\n",
      "success    1180\n",
      "failure       2\n",
      "Name: count, dtype: int64\n",
      "     -  ../data/llm-dump/misc/CHAP.xlsx (CHAP)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 470/470 [00:00<00:00, 1169.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status\n",
      "success    469\n",
      "failure      1\n",
      "Name: count, dtype: int64\n",
      "     -  ../data/llm-dump/misc/EJOUR.xlsx (EJOUR)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 1210.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status\n",
      "success    2\n",
      "Name: count, dtype: int64\n",
      "     -  ../data/llm-dump/misc/JFULL.xlsx (JFULL)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6051/6051 [00:07<00:00, 791.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status\n",
      "failure    4163\n",
      "success    1888\n",
      "Name: count, dtype: int64\n",
      "     -  ../data/llm-dump/misc/JOUR.xlsx (JOUR)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3483/3483 [00:02<00:00, 1418.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status\n",
      "success    3480\n",
      "failure       3\n",
      "Name: count, dtype: int64\n",
      "     -  ../data/llm-dump/misc/WEB.xlsx (WEB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:00<00:00, 785.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status\n",
      "success    31\n",
      "failure     1\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "llm_path = '../data/llm-dump'\n",
    "\n",
    "new_jtitles = Counter()\n",
    "\n",
    "for decade_folder in sorted(glob.glob(f'{llm_path}/*')):\n",
    "    #if '1990s' not in decade_folder:\n",
    "    #        continue\n",
    "    print(':::', decade_folder, ':::')\n",
    "\n",
    "    for spreadsheet_path in sorted(glob.glob(f'{decade_folder}/*.xlsx')):\n",
    "        df = pd.read_excel(spreadsheet_path, header=0, engine='openpyxl')\n",
    "        #n = 5000\n",
    "        #if len(df) > n:\n",
    "        #    df = df.sample(n)\n",
    "\n",
    "        if 'bibtex' not in df.columns:\n",
    "            continue\n",
    "    \n",
    "        ptype = os.path.basename(spreadsheet_path).replace('.xlsx', '')\n",
    "        print('     - ', spreadsheet_path, f'({ptype})')\n",
    "\n",
    "        if ptype not in ('BOOK', 'JOUR', 'CHAP', 'JFULL', 'EJOUR', 'ADVS', 'WEB'):\n",
    "        #if ptype != 'BOOK':\n",
    "            continue\n",
    "        \n",
    "        # parse the RIS (stored as JSON strings in the spreadsheet)\n",
    "        df['RIS'] = df['RIS'].apply(json.loads)\n",
    "\n",
    "        # clean (and deduplicate the bibtex returned by the LLM)\n",
    "        cleaned = []\n",
    "        for bt in df['bibtex']:\n",
    "            if isinstance(bt, str):\n",
    "                cleaned.append(clean_bibtex(bt))\n",
    "            else:\n",
    "                cleaned.append('')\n",
    "        df['bibtex-clean'] = cleaned\n",
    "\n",
    "        # Update the available RIS entries with newly structure info,\n",
    "        # returned by the LLM (and keep tracked of whether or not that is successful):\n",
    "        updated_ris, status = [], []\n",
    "        for ris, bibtex_str in tqdm(list(zip(df['RIS'], df['bibtex-clean']))):\n",
    "            if 'abstract' in ris:\n",
    "                ris['orig_abstract'] = ris['abstract']\n",
    "                del ris['abstract']\n",
    "            if isinstance(bibtex_str, str):\n",
    "                try:\n",
    "                    #print(bibtex_parse)\n",
    "                    bibtex_parse = parse_string(bibtex_str, 'bibtex')\n",
    "                    single_key = list(bibtex_parse.entries.keys())[0]\n",
    "                    updated = map_entry[ptype](ris.copy(), bibtex_parse.entries[single_key])\n",
    "\n",
    "                    # keep track of new journal titles which lack a normalized variant,\n",
    "                    # (unless the difference is only in capitalization):\n",
    "                    if ptype in 'JOUR' and 'journal_name' in updated and updated['journal_name'] not in existing_jtitles:\n",
    "                        try:\n",
    "                            updated['journal_name'] = lower2jtitles[updated['journal_name'].lower()]\n",
    "                        except KeyError:\n",
    "                            new_jtitles[updated['journal_name']] += 1\n",
    "                    \n",
    "                    updated['label'] = 'success'\n",
    "                    updated_ris.append(updated)\n",
    "                    status.append('success')\n",
    "                except Exception as e:\n",
    "                    #print(e)\n",
    "                    ris['label'] = f'failure ({str(e)})'\n",
    "                    updated_ris.append(ris)\n",
    "                    status.append('failure')\n",
    "            else:\n",
    "                ris['label'] = 'failure'\n",
    "                updated_ris.append(ris)\n",
    "                status.append('failure')\n",
    "\n",
    "        # store the newly merged information as a JSON string that holds a RIS entry:\n",
    "        df['consolidated'] = [json.dumps(r, indent=2, ensure_ascii=False) for r in updated_ris]\n",
    "        df['status'] = status\n",
    "\n",
    "        # re-encode the original RIS entry as a JSON string in the original column:\n",
    "        df['RIS'] = [json.dumps(d, indent=2, ensure_ascii=False) for d in df['RIS']]\n",
    "\n",
    "        # remove the cleaned bibtex string:\n",
    "        del df['bibtex-clean']\n",
    "\n",
    "        # output new spreadsheet:\n",
    "        df.to_excel(spreadsheet_path, index=False, header=True)\n",
    "\n",
    "        # Ensure that 'extra' field is correctly set as a list for each record\n",
    "        for record in updated_ris:\n",
    "            if 'extra' in record and not isinstance(record['extra'], str):\n",
    "                record['extra'] = ' /// '.join(record['extra'])\n",
    "\n",
    "        # output updated RIS file:\n",
    "        with open(f'{decade_folder}/{ptype}_consolidated.ris', 'w') as bibliography_file:\n",
    "            rispy.dump(updated_ris, bibliography_file, mapping=mappings)\n",
    "\n",
    "        # show the failure statistics:\n",
    "        print(df['status'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d759fd3",
   "metadata": {},
   "source": [
    "Extract journal titles for which we don't have a normalization yet and map them provionally to the closest available normalized title (using the Levenshtein distance):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71a03b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mappings = []\n",
    "#for nj, cnt in new_jtitles.items():\n",
    "#    distances = np.array([lev.distance(nj, oj) for oj in jtitle['normalized']])\n",
    "#    mappings.append([nj, cnt] + list(jtitle.iloc[np.argmin(distances)][['normalized', 'issn']]))\n",
    "\n",
    "#mappings = pd.DataFrame(mappings, columns=['raw title', 'count', 'normalized', 'issn'])\n",
    "#mappings = mappings.sort_values('count', ascending=False)\n",
    "#mappings.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61476c0",
   "metadata": {},
   "source": [
    "We save this spreadsheet for manual correction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1316bcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mappings.to_excel('../data/journal_titles_2ndBatch.xlsx', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe12a9ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849d4d7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c34be5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.12",
   "language": "python",
   "name": "py3.12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
