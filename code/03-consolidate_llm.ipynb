{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fifth-deployment",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "from collections import Counter\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import Levenshtein as lev\n",
    "import numpy as np\n",
    "\n",
    "import rispy\n",
    "from pybtex.database import parse_string\n",
    "from pylatexenc.latex2text import LatexNodes2Text\n",
    "conv = LatexNodes2Text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fa9b837",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_isbn(input_string):\n",
    "    \"\"\"\n",
    "    Extract an ISBN from an unstructured text string.\n",
    "    \n",
    "    The function searches for ISBN numbers that may include a check character 'X' at the end.\n",
    "    It recognizes ISBNs both with and without spaces or hyphens between segments.\n",
    "    \"\"\"\n",
    "    # Regular expression to match \"ISBN:\" followed by any combination of digits, hyphens, and possibly ending with an 'X'\n",
    "    pattern = r'ISBN:?\\s*([\\d\\-]+X?)'\n",
    "    \n",
    "    match = re.search(pattern, input_string)\n",
    "    if match:\n",
    "        return match.group(1)  # Return the matched part (ISBN number)\n",
    "    else:\n",
    "        return None  # No ISBN found following the \"ISBN:\" prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1c1f079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'90-801724-1-3'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_isbn(\"De herkomst van familienamen in Suriname, 1667-1863 / H. Speyer. - Voorburg : A & A Publishing, [1993]. - 45 p. : ill. ; 21 cm Met lit. opg. ISBN 90-801724-1-3.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f435a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_chapter(ris, bibt):\n",
    "    # make editors authors, if applicable:\n",
    "    if 'editor' in bibt.persons:\n",
    "        if 'author' in bibt.persons:\n",
    "            ris['first_authors'] = [conv.latex_to_text(str(editor)) for editor in bibt.persons['author']]\n",
    "        else:\n",
    "            if 'authors' in ris:\n",
    "                del ris['authors']\n",
    "        ris['secondary_authors'] = [conv.latex_to_text(str(editor)) for editor in bibt.persons['editor']]\n",
    "\n",
    "    if 'first_authors' in ris and 'secondary_authors' in ris:\n",
    "        if 'authors' in ris:\n",
    "            del ris['authors']\n",
    "\n",
    "    # add translators\n",
    "    if 'translator' in bibt.fields:\n",
    "        ris['tertiary_authors'] = conv.latex_to_text(bibt.fields['translator']).split(' and ')\n",
    "\n",
    "    for f in bibt.fields:\n",
    "        bibt.fields[f] = conv.latex_to_text(bibt.fields[f])\n",
    "    \n",
    "    # replace non-distinct title with parsed journal title:\n",
    "    if 'title' in bibt.fields:\n",
    "        ris['notes_abstract'] = ris['title']\n",
    "        ris['title'] = bibt.fields['title']\n",
    "\n",
    "    if 'booktitle' in bibt.fields:\n",
    "        ris['secondary_title'] = bibt.fields['booktitle']\n",
    "    \n",
    "    if 'pagetotal' in bibt.fields:\n",
    "        ris['end_page'] = bibt.fields['pagetotal']\n",
    "    \n",
    "    if 'pages' in bibt.fields:\n",
    "        pages = bibt.fields['pages'].split('-')\n",
    "        if len(pages) == 2:\n",
    "            ris['start_page'] = pages[0]\n",
    "            ris['end_page'] = pages[1]\n",
    "        else:\n",
    "            ris['end_page'] = bibt.fields['pages']\n",
    "    \n",
    "    if 'publisher' in bibt.fields:\n",
    "        ris['publisher'] = bibt.fields['publisher']\n",
    "\n",
    "    if 'place' in bibt.fields:\n",
    "        ris['place_published'] = bibt.fields['place']\n",
    "\n",
    "    if 'address' in bibt.fields:\n",
    "        ris['place_published'] = bibt.fields['address']\n",
    "    \n",
    "    if 'location' in bibt.fields:\n",
    "        ris['place_published'] = bibt.fields['location']\n",
    "\n",
    "    if 'series' in bibt.fields:\n",
    "        ris['tertiary_title'] = bibt.fields['series']\n",
    "\n",
    "    if 'volume' in bibt.fields:\n",
    "        ris['volume'] = bibt.fields['volume']\n",
    "\n",
    "    if 'number' in bibt.fields:\n",
    "        ris['number'] = bibt.fields['number']\n",
    "\n",
    "    if 'edition' in bibt.fields:\n",
    "        ris['edition'] = bibt.fields['edition']\n",
    "    \n",
    "    return ris"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6c45da",
   "metadata": {},
   "source": [
    "Collect already available normalizations for journal titles (so that we can find out below which one we miss):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10036c79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>secondary_title</th>\n",
       "      <th>normalized</th>\n",
       "      <th>count</th>\n",
       "      <th>issn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ons erfdeel: kultureel tijdschrift voor Zuidvl...</td>\n",
       "      <td>Ons erfdeel</td>\n",
       "      <td>2660.0</td>\n",
       "      <td>0030-2651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dietsche warande en Belfort: tijdschrift voor ...</td>\n",
       "      <td>Dietsche warande en Belfort</td>\n",
       "      <td>2461.0</td>\n",
       "      <td>0012-2645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>De nieuwe taalgids: tweemaandelijks tijdschrif...</td>\n",
       "      <td>De nieuwe taalgids</td>\n",
       "      <td>2359.0</td>\n",
       "      <td>0028-9922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bzzlletin; Stichting BZZTôH Teater. Voorburg: ...</td>\n",
       "      <td>Bzzlletin</td>\n",
       "      <td>1638.0</td>\n",
       "      <td>0165-0858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Poëziekrant: tweemaandelijks tijdschrift. Gent...</td>\n",
       "      <td>Poëziekrant</td>\n",
       "      <td>1573.0</td>\n",
       "      <td>2030-0638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Onze taal: maandblad van het Genootschap Onze ...</td>\n",
       "      <td>Onze taal</td>\n",
       "      <td>1322.0</td>\n",
       "      <td>0165-7828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Vlaanderen: tweemaandelijks tijdschrift voor k...</td>\n",
       "      <td>Vlaanderen</td>\n",
       "      <td>1312.0</td>\n",
       "      <td>0042-7683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>De gids: nieuwe vaderlandsche letteroefeningen...</td>\n",
       "      <td>De gids</td>\n",
       "      <td>1249.0</td>\n",
       "      <td>0016-9730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Levende talen: berichten en mededelingen van d...</td>\n",
       "      <td>Levende talen</td>\n",
       "      <td>1239.0</td>\n",
       "      <td>0024-1539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tijdschrift voor Nederlandse taal- en letterku...</td>\n",
       "      <td>Tijdschrift voor Nederlandse taal- en letterkunde</td>\n",
       "      <td>962.0</td>\n",
       "      <td>0040-7550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Literatuur: tijdschrift over Nederlandse lette...</td>\n",
       "      <td>Literatuur</td>\n",
       "      <td>926.0</td>\n",
       "      <td>0168-7050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Leesidee: kritisch-bibliografisch tijdschrift;...</td>\n",
       "      <td>Leesidee</td>\n",
       "      <td>918.0</td>\n",
       "      <td>1370-1053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Maatstaf: maandblad voor letteren. 's-Gravenha...</td>\n",
       "      <td>Maatstaf</td>\n",
       "      <td>886.0</td>\n",
       "      <td>0024-8851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>De periscoop: spiegel van het literair en arti...</td>\n",
       "      <td>De periscoop</td>\n",
       "      <td>853.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Het boek van nu: maandblad voor boekenvrienden...</td>\n",
       "      <td>Het boek van nu</td>\n",
       "      <td>813.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Kreatief: driemaandelijks literair- en kunstkr...</td>\n",
       "      <td>Kreatief</td>\n",
       "      <td>808.0</td>\n",
       "      <td>0772-6376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Critisch bulletin: maandblad voor letterkundig...</td>\n",
       "      <td>Critisch bulletin</td>\n",
       "      <td>773.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Biekorf: dat is een leer- en leesblad voor all...</td>\n",
       "      <td>Biekorf</td>\n",
       "      <td>762.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Kruispunt: driemaandelijks tijdschrift. Brugge...</td>\n",
       "      <td>Kruispunt</td>\n",
       "      <td>745.0</td>\n",
       "      <td>0774-7233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Neerlandia: orgaan van het Algemeen Nederlands...</td>\n",
       "      <td>Neerlandia</td>\n",
       "      <td>729.0</td>\n",
       "      <td>0028-2383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Tirade. Amsterdam: Van Oorschot, 1957-....</td>\n",
       "      <td>Tirade</td>\n",
       "      <td>705.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>De Vlaamsche gids: algemeen tweemaandelijksch ...</td>\n",
       "      <td>De Vlaamsche gids</td>\n",
       "      <td>685.0</td>\n",
       "      <td>0042-7675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Septentrion: revue de culture néerlandaise. Re...</td>\n",
       "      <td>Septentrion</td>\n",
       "      <td>675.0</td>\n",
       "      <td>0771-8934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Ontmoeting: letterkundig en algemeen-cultureel...</td>\n",
       "      <td>Ontmoeting</td>\n",
       "      <td>650.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Spiegel der letteren: tijdschrift voor Nederla...</td>\n",
       "      <td>Spiegel der letteren</td>\n",
       "      <td>643.0</td>\n",
       "      <td>0038-7479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Spektator: tijdschrift voor Neerlandistiek. Gr...</td>\n",
       "      <td>Spektator</td>\n",
       "      <td>631.0</td>\n",
       "      <td>0165-084X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Dooijes, Dick. Boektypografische verkenningen:...</td>\n",
       "      <td>Dooijes, Dick</td>\n",
       "      <td>603.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Yang: tijdschrift voor literatuur en kommunika...</td>\n",
       "      <td>Yang</td>\n",
       "      <td>602.0</td>\n",
       "      <td>0775-2830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Taal en tongval: tijdschrift voor de studie va...</td>\n",
       "      <td>Taal en tongval</td>\n",
       "      <td>561.0</td>\n",
       "      <td>0039-8691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Verslagen en mededelingen van de Koninklijke A...</td>\n",
       "      <td>Verslagen en mededelingen van de Koninklijke A...</td>\n",
       "      <td>559.0</td>\n",
       "      <td>0770-786X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      secondary_title  \\\n",
       "0   Ons erfdeel: kultureel tijdschrift voor Zuidvl...   \n",
       "1   Dietsche warande en Belfort: tijdschrift voor ...   \n",
       "2   De nieuwe taalgids: tweemaandelijks tijdschrif...   \n",
       "3   Bzzlletin; Stichting BZZTôH Teater. Voorburg: ...   \n",
       "4   Poëziekrant: tweemaandelijks tijdschrift. Gent...   \n",
       "5   Onze taal: maandblad van het Genootschap Onze ...   \n",
       "6   Vlaanderen: tweemaandelijks tijdschrift voor k...   \n",
       "7   De gids: nieuwe vaderlandsche letteroefeningen...   \n",
       "8   Levende talen: berichten en mededelingen van d...   \n",
       "9   Tijdschrift voor Nederlandse taal- en letterku...   \n",
       "10  Literatuur: tijdschrift over Nederlandse lette...   \n",
       "11  Leesidee: kritisch-bibliografisch tijdschrift;...   \n",
       "12  Maatstaf: maandblad voor letteren. 's-Gravenha...   \n",
       "13  De periscoop: spiegel van het literair en arti...   \n",
       "14  Het boek van nu: maandblad voor boekenvrienden...   \n",
       "15  Kreatief: driemaandelijks literair- en kunstkr...   \n",
       "16  Critisch bulletin: maandblad voor letterkundig...   \n",
       "17  Biekorf: dat is een leer- en leesblad voor all...   \n",
       "18  Kruispunt: driemaandelijks tijdschrift. Brugge...   \n",
       "19  Neerlandia: orgaan van het Algemeen Nederlands...   \n",
       "20         Tirade. Amsterdam: Van Oorschot, 1957-....   \n",
       "21  De Vlaamsche gids: algemeen tweemaandelijksch ...   \n",
       "22  Septentrion: revue de culture néerlandaise. Re...   \n",
       "23  Ontmoeting: letterkundig en algemeen-cultureel...   \n",
       "24  Spiegel der letteren: tijdschrift voor Nederla...   \n",
       "25  Spektator: tijdschrift voor Neerlandistiek. Gr...   \n",
       "26  Dooijes, Dick. Boektypografische verkenningen:...   \n",
       "27  Yang: tijdschrift voor literatuur en kommunika...   \n",
       "28  Taal en tongval: tijdschrift voor de studie va...   \n",
       "29  Verslagen en mededelingen van de Koninklijke A...   \n",
       "\n",
       "                                           normalized   count       issn  \n",
       "0                                         Ons erfdeel  2660.0  0030-2651  \n",
       "1                         Dietsche warande en Belfort  2461.0  0012-2645  \n",
       "2                                  De nieuwe taalgids  2359.0  0028-9922  \n",
       "3                                           Bzzlletin  1638.0  0165-0858  \n",
       "4                                         Poëziekrant  1573.0  2030-0638  \n",
       "5                                           Onze taal  1322.0  0165-7828  \n",
       "6                                          Vlaanderen  1312.0  0042-7683  \n",
       "7                                             De gids  1249.0  0016-9730  \n",
       "8                                       Levende talen  1239.0  0024-1539  \n",
       "9   Tijdschrift voor Nederlandse taal- en letterkunde   962.0  0040-7550  \n",
       "10                                         Literatuur   926.0  0168-7050  \n",
       "11                                           Leesidee   918.0  1370-1053  \n",
       "12                                           Maatstaf   886.0  0024-8851  \n",
       "13                                       De periscoop   853.0        NaN  \n",
       "14                                    Het boek van nu   813.0        NaN  \n",
       "15                                           Kreatief   808.0  0772-6376  \n",
       "16                                  Critisch bulletin   773.0        NaN  \n",
       "17                                            Biekorf   762.0        NaN  \n",
       "18                                          Kruispunt   745.0  0774-7233  \n",
       "19                                         Neerlandia   729.0  0028-2383  \n",
       "20                                             Tirade   705.0        NaN  \n",
       "21                                  De Vlaamsche gids   685.0  0042-7675  \n",
       "22                                        Septentrion   675.0  0771-8934  \n",
       "23                                         Ontmoeting   650.0        NaN  \n",
       "24                               Spiegel der letteren   643.0  0038-7479  \n",
       "25                                          Spektator   631.0  0165-084X  \n",
       "26                                      Dooijes, Dick   603.0        NaN  \n",
       "27                                               Yang   602.0  0775-2830  \n",
       "28                                    Taal en tongval   561.0  0039-8691  \n",
       "29  Verslagen en mededelingen van de Koninklijke A...   559.0  0770-786X  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jtitle = pd.read_excel('../data/journal_titles_master.xlsx')\n",
    "existing_jtitles = set(jtitle['normalized'])\n",
    "lower2jtitles = dict(zip(jtitle['normalized'].str.lower(), jtitle['normalized']))\n",
    "jtitle.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb85e467",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_journal(ris, bibt):\n",
    "    \"\"\"\n",
    "    Merges the newly structured information in the bibtex returned\n",
    "    by the LLM into the already available RIS entry from the dump.\n",
    "    Reliably structured information (e.g. authors, year, keywords, ...)\n",
    "    from the RIS entries is maximally retained.\n",
    "    \"\"\"\n",
    "    #print(ris)\n",
    "    #print(bibt)\n",
    "    #print('===============================================')\n",
    "\n",
    "    for f in bibt.fields:\n",
    "        bibt.fields[f] = conv.latex_to_text(bibt.fields[f])\n",
    "    \n",
    "    # replace unstrucuted title with parsed journal title (if available):\n",
    "    if 'title' in bibt.fields:\n",
    "        # keep track of original title description:\n",
    "        ris['notes_abstract'] = ris['title']\n",
    "        ris['title'] = bibt.fields['title']\n",
    "        if ris['title'].endswith(','):\n",
    "            ris['title'] = ris['title'][:-1]\n",
    "        if ris['title'].strip().lower() in ('in', 'untitled', 'title of the article', 'title of the article (if provided)'):\n",
    "            ris['title'] = ''\n",
    "    \n",
    "    # parse pagination information:\n",
    "    if 'pagetotal' in bibt.fields:\n",
    "        ris['end_page'] = bibt.fields['pagetotal']\n",
    "    if 'pages' in bibt.fields:\n",
    "        pages = bibt.fields['pages'].split('-')\n",
    "        if len(pages) == 2:\n",
    "            ris['start_page'] = pages[0]\n",
    "            ris['end_page'] = pages[1]\n",
    "        else:\n",
    "            ris['end_page'] = bibt.fields['pages']\n",
    "\n",
    "    # collect parsed journal title (unless we had that information already, which will be more reliable)\n",
    "    if 'secondary_title' not in ris and 'journal' in bibt.fields:\n",
    "        journal = bibt.fields['journal']\n",
    "        # sometimes place of publication of the journal is added: we remove that\n",
    "        journal = journal.split('(')[0].strip()\n",
    "        journal = journal.split('[')[0].strip()\n",
    "        ris['journal_name'] = journal\n",
    "    elif 'secondary_title' in ris and 'journal' in bibt.fields:\n",
    "        ris['journal_name'] = ris['secondary_title']\n",
    "        del ris['secondary_title']\n",
    "\n",
    "    if 'journal_name' in ris:\n",
    "        jn = ris['journal_name']\n",
    "        if jn.startswith('\"') and jn.endswith('\",'):\n",
    "            jn = jn[1:-2]\n",
    "        if jn.count('\"') == 1:\n",
    "            jn = jn.replace('\"', '')\n",
    "        ris['journal_name'] = jn\n",
    "    \n",
    "    # collect information on volume and issue\n",
    "    if 'volume' in bibt.fields:\n",
    "        ris['volume'] = bibt.fields['volume']\n",
    "    if 'number' in bibt.fields:\n",
    "        ris['number'] = bibt.fields['number']\n",
    "    if 'number' not in bibt.fields and 'issue' in bibt.fields:\n",
    "        ris['number'] = bibt.fields['issue']\n",
    "    \n",
    "    if 'volume' in ris and not 'number' in ris:\n",
    "        ris['number'] = ris['volume']\n",
    "        del ris['volume']\n",
    "    \n",
    "    return ris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "daec9dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_book(ris, bibt):\n",
    "    # extract ISBN for abstract field, if available:\n",
    "    if 'abstract' in ris:\n",
    "        abstract = ris['abstract']\n",
    "        isbn = extract_isbn(abstract.strip())\n",
    "        if isbn:\n",
    "            ris['issn'] = isbn\n",
    "        else:\n",
    "            isbn = extract_isbn(ris['title'])\n",
    "            if isbn:\n",
    "                ris['issn'] = isbn\n",
    "\n",
    "    # make editors authors, if applicable:\n",
    "    if 'editor' in bibt.persons:\n",
    "        if 'author' in bibt.persons:\n",
    "            ris['first_authors'] = [conv.latex_to_text(str(editor)) for editor in bibt.persons['author']]\n",
    "        else:\n",
    "            if 'author' in ris:\n",
    "                del ris['author']\n",
    "            if 'authors' in ris:\n",
    "                del ris['authors']\n",
    "        ris['secondary_authors'] = [conv.latex_to_text(str(editor)) for editor in bibt.persons['editor']]\n",
    "\n",
    "    if 'first_authors' in ris and 'secondary_authors' in ris:\n",
    "        if 'author' in ris:\n",
    "            del ris['author']\n",
    "        if 'authors' in ris:\n",
    "            del ris['authors']\n",
    "\n",
    "    # add translators\n",
    "    if 'translator' in bibt.fields:\n",
    "        ris['tertiary_authors'] = conv.latex_to_text(bibt.fields['translator']).split(' and ')\n",
    "        if 'author' in ris:\n",
    "            del ris['author']\n",
    "        if 'first_authors' in ris:\n",
    "            del ris['first_authors']\n",
    "\n",
    "    for f in bibt.fields:\n",
    "        bibt.fields[f] = conv.latex_to_text(bibt.fields[f])\n",
    "    \n",
    "    # replace non-distinct title with parsed book title:\n",
    "    if 'title' in bibt.fields and bibt.fields['title']:\n",
    "        ris['notes_abstract'] = ris['title']\n",
    "        ris['title'] = bibt.fields['title']\n",
    "    elif 'booktitle' in bibt.fields and bibt.fields['booktitle']:\n",
    "        ris['notes_abstract'] = ris['title']\n",
    "        ris['title'] = bibt.fields['booktitle']\n",
    "    \n",
    "    if 'pagetotal' in bibt.fields:\n",
    "        ris['end_page'] = bibt.fields['pagetotal']\n",
    "    \n",
    "    if 'pages' in bibt.fields:\n",
    "        ris['end_page'] = bibt.fields['pages']\n",
    "    \n",
    "    if 'publisher' in bibt.fields:\n",
    "        ris['publisher'] = bibt.fields['publisher']\n",
    "\n",
    "    if 'place' in bibt.fields:\n",
    "        ris['place_published'] = bibt.fields['place']\n",
    "\n",
    "    if 'place' in bibt.fields:\n",
    "        place = bibt.fields['place']\n",
    "        if '[' + place + ']' in ris['notes_abstract']:\n",
    "            place = '[' + place + ']'\n",
    "        ris['place_published'] = place\n",
    "\n",
    "    if 'address' in bibt.fields:\n",
    "        ris['place_published'] = bibt.fields['address']\n",
    "    \n",
    "    if 'location' in bibt.fields:\n",
    "        ris['place_published'] = bibt.fields['location']\n",
    "\n",
    "    if 'series' in bibt.fields:\n",
    "        if ';' in bibt.fields['series']:\n",
    "            series, vol = [e.strip() for e in bibt.fields['series'].split(';', maxsplit=1)]\n",
    "            ris['secondary_title'] = series\n",
    "            ris['volume'] = vol\n",
    "        else:\n",
    "            ris['secondary_title'] = bibt.fields['series']\n",
    "\n",
    "    if 'volume' in bibt.fields:\n",
    "        ris['volume'] = bibt.fields['volume']\n",
    "\n",
    "    if 'number' in bibt.fields:\n",
    "        ris['number'] = bibt.fields['number']\n",
    "\n",
    "    if 'edition' in bibt.fields:\n",
    "        ris['edition'] = bibt.fields['edition']\n",
    "    \n",
    "    return ris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72dd0f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_jfull(ris, bibt):\n",
    "    for f in bibt.fields:\n",
    "        bibt.fields[f] = conv.latex_to_text(bibt.fields[f])\n",
    "    \n",
    "    if 'abstract' in ris:\n",
    "        abstract = ris['abstract']\n",
    "\n",
    "    # replace non-distinct title with parsed book title:\n",
    "    if 'title' in bibt.fields and bibt.fields['title']:\n",
    "        ris['notes_abstract'] = ris['title']\n",
    "        ris['title'] = bibt.fields['title']\n",
    "    elif 'booktitle' in bibt.fields and bibt.fields['booktitle']:\n",
    "        ris['notes_abstract'] = ris['title']\n",
    "        ris['title'] = bibt.fields['booktitle']\n",
    "\n",
    "    if 'first_authors' in ris:\n",
    "        ris['secondary_authors'] = ris['first_authors']\n",
    "        del ris['first_authors']\n",
    "    \n",
    "    for f in bibt.fields:\n",
    "        bibt.fields[f] = conv.latex_to_text(bibt.fields[f])\n",
    "    \n",
    "    # pagination information:\n",
    "    if 'pagetotal' in bibt.fields:\n",
    "        ris['end_page'] = bibt.fields['pagetotal']\n",
    "    if 'pages' in bibt.fields:\n",
    "        ris['end_page'] = bibt.fields['pages']\n",
    "    \n",
    "    # publisher information:\n",
    "    if 'publisher' in bibt.fields:\n",
    "        ris['publisher'] = bibt.fields['publisher']\n",
    "\n",
    "    # place of publication:\n",
    "    if 'place' in bibt.fields:\n",
    "        ris['place_published'] = bibt.fields['place']\n",
    "    if 'place' in bibt.fields:\n",
    "        place = bibt.fields['place']\n",
    "        if '[' + place + ']' in ris['notes_abstract']:\n",
    "            place = '[' + place + ']'\n",
    "        ris['place_published'] = place\n",
    "    if 'address' in bibt.fields:\n",
    "        ris['place_published'] = bibt.fields['address']\n",
    "    if 'location' in bibt.fields:\n",
    "        ris['place_published'] = bibt.fields['location']\n",
    "\n",
    "    if 'volume' in bibt.fields:\n",
    "        ris['volume'] = bibt.fields['volume']\n",
    "\n",
    "    if 'number' in bibt.fields:\n",
    "        ris['number'] = bibt.fields['number']\n",
    "    \n",
    "    return ris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2236510",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_entry = {\n",
    "             'JOUR': map_journal,\n",
    "             'CHAP': map_chapter,\n",
    "             'BOOK': map_book,\n",
    "             'JFULL': map_jfull,\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcd701a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deduplicate_bibtex(bibt):\n",
    "    \"\"\"\n",
    "    Deduplicate repeated fields in the bibtex returned by the LLM.\n",
    "    We only keep the first appearance of a given field.\n",
    "    \"\"\"\n",
    "    lines, fields = [], set()\n",
    "    for line in bibt.strip().split('\\n'):\n",
    "        if line.startswith('@') or line == '}':\n",
    "            lines.append(line)\n",
    "        else:\n",
    "            field = line.split('=')[0].strip()\n",
    "            if field not in fields:\n",
    "                lines.append(line)\n",
    "                fields.add(field)\n",
    "\n",
    "    clean = '\\n'.join([l for l in lines if l])\n",
    "    if not clean.strip().endswith('}'):\n",
    "        clean += '\\n}\\n'\n",
    "    \n",
    "    return clean\n",
    "\n",
    "\n",
    "def clean_bibtex(bibt):\n",
    "    \"\"\"\n",
    "    Attempts to correct some common syntactic errors in the bibtex\n",
    "    returned by the LLM (which cause the pybtex parser to fail).\n",
    "    \"\"\"\n",
    "    if not bibt:\n",
    "        return ''\n",
    "    \n",
    "    # remove erroneous markdown syntax:\n",
    "    bibt = bibt.replace('```bibtex', '').replace('```', '').replace(\"```tex\", '')\n",
    "    \n",
    "    # sometimes mutliple bibtexs are created: we only keep the first one\n",
    "    bibt = [b for b in bibt.split('@') if b.strip()]\n",
    "    bibt = '@' + bibt[0]\n",
    "\n",
    "    lines = []\n",
    "    for line in bibt.strip().split('\\n'):\n",
    "        l = line.strip()\n",
    "\n",
    "        # take care of spaces in the bibtex key:\n",
    "        if l.startswith('@') and ' ' in l:\n",
    "            line = ''.join(line.split())\n",
    "        \n",
    "        # fix missing entry keys:\n",
    "        if l in ('@article{,', '@article{'):\n",
    "            lines.append('@article{xxx,')\n",
    "            continue\n",
    "        if l in ('@book{,', '@book{'):\n",
    "            lines.append('@book{xxx,')\n",
    "            continue\n",
    "        if l in ('@incollection{,', '@incollection{'):\n",
    "            lines.append('@incollection{xxx,')\n",
    "            continue\n",
    "\n",
    "        # common errors:\n",
    "        if l.endswith(']'):\n",
    "            line += '},'\n",
    "            lines.append(line)\n",
    "            continue\n",
    "        line = line.replace('{ )', '{}')\n",
    "        if l.endswith(\"',\"):\n",
    "            line = line[:-2] + '},'\n",
    "        \n",
    "        # ensure that end-of-line syntax is respected:\n",
    "        if l != '}':\n",
    "            if not l.endswith('},'):\n",
    "                if l.endswith('}'):\n",
    "                    line += ','\n",
    "                elif not l.endswith('}') and not l.endswith(','):\n",
    "                    line += '},'\n",
    "            if l.endswith('),'):\n",
    "                line = line.replace('),', ')},')\n",
    "        \n",
    "        # add missing curly brackets:\n",
    "        if '=' in l and (not '{' in l or not '}' in l):\n",
    "            k, v = [e.strip() for e in l.split('=')][:2]\n",
    "            v.replace(',', '')\n",
    "            line = '  ' + k + '=' + '{' + v + '},'\n",
    "        \n",
    "        # remove lines with empty values:\n",
    "        if '= {},' in l:\n",
    "            continue\n",
    "\n",
    "        if ' &' in line:\n",
    "            line = line.replace(' &', ' \\&')\n",
    "        \n",
    "        # correct curly bracket syntax in title field:\n",
    "        if l.startswith('title') and l.count('}') > 1:\n",
    "            k, v = [e.strip() for e in l.split('=')][:2]\n",
    "            v = v.replace('{', '').replace('}', '')\n",
    "            line = '  ' + k + '=' + '{' + v + '},'\n",
    "\n",
    "        # correct syntax:\n",
    "        if '\",' in l and '=' in l:\n",
    "            k, v = [e.strip() for e in l.split('=')][:2]\n",
    "            if v.startswith('\"') and v.endswith('\",'):\n",
    "                v = v[1:-2]\n",
    "            line = '  ' + k + '=' + '{' + v + '},'\n",
    "\n",
    "        lines.append(line)\n",
    "\n",
    "    # recompose the lines of the bibtex entry:\n",
    "    clean = '\\n'.join([l for l in lines if l])\n",
    "    if not clean.strip().endswith('}'):\n",
    "        clean += '\\n}\\n'\n",
    "    \n",
    "    # return the deduplicated version of the bibtex entry:\n",
    "    return deduplicate_bibtex(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4139264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@article{smit1951,\n",
      "  author = {Van Duinkerken, Anton},\n",
      "  title = {Over: Ternauwernood},\n",
      "  journal = {Critisch Bulletin},\n",
      "  volume = {18},\n",
      "  number = {10},\n",
      "  month = {October},\n",
      "  year = {1951},\n",
      "  pages = {462-467},\n",
      "  publisher = {Utrecht [etc.]},\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "d = \"\"\"@article{smit1951,\n",
    "  author = {Van Duinkerken, Anton},\n",
    "  title = {Over: Ternauwernood},\n",
    "  journal = {Critisch Bulletin},\n",
    "  volume = {18},\n",
    "  number = {10},\n",
    "  month = {October},\n",
    "  year = {1951},\n",
    "  pages = {462-467},\n",
    "  publisher = {Utrecht [etc.]\n",
    "}\"\"\"\n",
    "print(clean_bibtex(d))\n",
    "assert parse_string(clean_bibtex(d), 'bibtex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7237278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@article{xxx,\n",
      "  title={Uitreiking Taaluniepenning 1991},\n",
      "  author={unknown},\n",
      "  journal={Publikatieblad; Nederlandse Taalunie},\n",
      "  year={1992},\n",
      "  volume={23},\n",
      "  number={jan},\n",
      "  pages={1-9},\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "s = \"\"\"@article{,\n",
    "  title={Uitreiking Taaluniepenning 1991},\n",
    "  author={unknown},\n",
    "  journal={Publikatieblad; Nederlandse Taalunie},\n",
    "  year={1992},\n",
    "  volume={23},\n",
    "  number={jan},\n",
    "  pages={1-9}\n",
    "}\"\"\"\n",
    "\n",
    "print(clean_bibtex(s))\n",
    "assert parse_string(clean_bibtex(s), 'bibtex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "739c482c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "::: ../data/llm-dump/1940s :::\n",
      "     -  ../data/llm-dump/1940s/BOOK.xlsx (BOOK)\n",
      "     -  ../data/llm-dump/1940s/CHAP.xlsx (CHAP)\n",
      "     -  ../data/llm-dump/1940s/JFULL.xlsx (JFULL)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:00<00:00, 961.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status\n",
      "success    68\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     -  ../data/llm-dump/1940s/JOUR.xlsx (JOUR)\n",
      "::: ../data/llm-dump/1950s :::\n",
      "     -  ../data/llm-dump/1950s/BOOK.xlsx (BOOK)\n",
      "     -  ../data/llm-dump/1950s/CHAP.xlsx (CHAP)\n",
      "     -  ../data/llm-dump/1950s/JFULL.xlsx (JFULL)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:00<00:00, 733.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status\n",
      "success    17\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     -  ../data/llm-dump/1950s/JOUR.xlsx (JOUR)\n",
      "::: ../data/llm-dump/1960s :::\n",
      "     -  ../data/llm-dump/1960s/BOOK.xlsx (BOOK)\n",
      "     -  ../data/llm-dump/1960s/CHAP.xlsx (CHAP)\n",
      "     -  ../data/llm-dump/1960s/JFULL.xlsx (JFULL)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 190/190 [00:00<00:00, 941.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "syntax error in line 1: '(' or '{' expected\n",
      "status\n",
      "success    189\n",
      "failure      1\n",
      "Name: count, dtype: int64\n",
      "     -  ../data/llm-dump/1960s/JOUR.xlsx (JOUR)\n",
      "::: ../data/llm-dump/1970s :::\n",
      "     -  ../data/llm-dump/1970s/BOOK.xlsx (BOOK)\n",
      "     -  ../data/llm-dump/1970s/CHAP.xlsx (CHAP)\n",
      "     -  ../data/llm-dump/1970s/JFULL.xlsx (JFULL)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 67/273 [00:00<00:00, 669.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "syntax error in line 1: '(' or '{' expected"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 273/273 [00:00<00:00, 866.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "status\n",
      "success    272\n",
      "failure      1\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     -  ../data/llm-dump/1970s/JOUR.xlsx (JOUR)\n",
      "::: ../data/llm-dump/1980s :::\n",
      "     -  ../data/llm-dump/1980s/ADVS.xlsx (ADVS)\n",
      "     -  ../data/llm-dump/1980s/BOOK.xlsx (BOOK)\n",
      "     -  ../data/llm-dump/1980s/CHAP.xlsx (CHAP)\n",
      "     -  ../data/llm-dump/1980s/JFULL.xlsx (JFULL)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 70/619 [00:00<00:00, 696.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "syntax error in line 11: '}' expected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 228/619 [00:00<00:00, 772.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "syntax error in line 1: '(' or '{' expected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 407/619 [00:00<00:00, 844.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "syntax error in line 1: '(' or '{' expected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 585/619 [00:00<00:00, 862.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "syntax error in line 1: '(' or '{' expected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 619/619 [00:00<00:00, 831.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status\n",
      "success    615\n",
      "failure      4\n",
      "Name: count, dtype: int64\n",
      "     -  ../data/llm-dump/1980s/JOUR.xlsx (JOUR)\n",
      "     -  ../data/llm-dump/1980s/WEB.xlsx (WEB)\n",
      "::: ../data/llm-dump/1990s :::\n",
      "     -  ../data/llm-dump/1990s/ADVS.xlsx (ADVS)\n",
      "     -  ../data/llm-dump/1990s/BOOK.xlsx (BOOK)\n",
      "     -  ../data/llm-dump/1990s/CHAP.xlsx (CHAP)\n",
      "     -  ../data/llm-dump/1990s/EJOUR.xlsx (EJOUR)\n",
      "     -  ../data/llm-dump/1990s/JFULL.xlsx (JFULL)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 551/660 [00:00<00:00, 804.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "syntax error in line 8: '=' expected\n",
      "syntax error in line 13: '}' expected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 660/660 [00:00<00:00, 786.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "syntax error in line 11: premature end of file\n",
      "status\n",
      "success    657\n",
      "failure      3\n",
      "Name: count, dtype: int64\n",
      "     -  ../data/llm-dump/1990s/JOUR.xlsx (JOUR)\n",
      "     -  ../data/llm-dump/1990s/WEB.xlsx (WEB)\n",
      "::: ../data/llm-dump/2000s :::\n",
      "     -  ../data/llm-dump/2000s/ADVS.xlsx (ADVS)\n",
      "     -  ../data/llm-dump/2000s/BOOK.xlsx (BOOK)\n",
      "     -  ../data/llm-dump/2000s/CHAP.xlsx (CHAP)\n",
      "     -  ../data/llm-dump/2000s/EJOUR.xlsx (EJOUR)\n",
      "     -  ../data/llm-dump/2000s/JFULL.xlsx (JFULL)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 245/479 [00:00<00:00, 818.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Too many commas in 'Jimmy Koppen, Marnix Beyen, Christel Stalpaert, Harry Van Velthoven'\n",
      "Too many commas in '[redactie: Toef Jaeger, Menno Lievers, Ilja Leonard Pfeijffer, Allard Schröder]'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 479/479 [00:00<00:00, 821.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "syntax error in line 4: '=' expected\n",
      "syntax error in line 4: '=' expected\n",
      "Too many commas in 'Floris Cavyn, Evelyne Coussens (eindredactie), Wouter Hillaert (hoofd- en eindredactie), et al.'\n",
      "Too many commas in 'Georges Martyn, Gretha Donker, Sjoerd Faber, Dirk Heirbaut'\n",
      "status\n",
      "success    473\n",
      "failure      6\n",
      "Name: count, dtype: int64\n",
      "     -  ../data/llm-dump/2000s/JOUR.xlsx (JOUR)\n",
      "     -  ../data/llm-dump/2000s/WEB.xlsx (WEB)\n",
      "::: ../data/llm-dump/2010s :::\n",
      "     -  ../data/llm-dump/2010s/ADVS.xlsx (ADVS)\n",
      "     -  ../data/llm-dump/2010s/BOOK.xlsx (BOOK)\n",
      "     -  ../data/llm-dump/2010s/CHAP.xlsx (CHAP)\n",
      "     -  ../data/llm-dump/2010s/EJOUR.xlsx (EJOUR)\n",
      "     -  ../data/llm-dump/2010s/JFULL.xlsx (JFULL)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 67/442 [00:00<00:00, 666.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "syntax error in line 10: premature end of file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 239/442 [00:00<00:00, 805.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "syntax error in line 4: premature end of file\n",
      "syntax error in line 1: entry key expected\n",
      "syntax error in line 5: premature end of file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 442/442 [00:00<00:00, 819.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "syntax error in line 6: premature end of file\n",
      "syntax error in line 6: premature end of file\n",
      "Too many commas in 'Gábor Pusztai, Réka Bozzay, Jaap Doedens, Annyke de Jong, Márta Kántor-Faragó \\\\& Gert Loosen'\n",
      "status\n",
      "success    435\n",
      "failure      7\n",
      "Name: count, dtype: int64\n",
      "     -  ../data/llm-dump/2010s/JOUR.xlsx (JOUR)\n",
      "     -  ../data/llm-dump/2010s/WEB.xlsx (WEB)\n",
      "::: ../data/llm-dump/2020s :::\n",
      "     -  ../data/llm-dump/2020s/ADVS.xlsx (ADVS)\n",
      "     -  ../data/llm-dump/2020s/BOOK.xlsx (BOOK)\n",
      "     -  ../data/llm-dump/2020s/CHAP.xlsx (CHAP)\n",
      "     -  ../data/llm-dump/2020s/EJOUR.xlsx (EJOUR)\n",
      "     -  ../data/llm-dump/2020s/JFULL.xlsx (JFULL)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 161/161 [00:00<00:00, 900.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status\n",
      "success    161\n",
      "Name: count, dtype: int64\n",
      "     -  ../data/llm-dump/2020s/JOUR.xlsx (JOUR)\n",
      "     -  ../data/llm-dump/2020s/WEB.xlsx (WEB)\n",
      "::: ../data/llm-dump/misc :::\n",
      "     -  ../data/llm-dump/misc/ADVS.xlsx (ADVS)\n",
      "     -  ../data/llm-dump/misc/BOOK.xlsx (BOOK)\n",
      "     -  ../data/llm-dump/misc/CHAP.xlsx (CHAP)\n",
      "     -  ../data/llm-dump/misc/EJOUR.xlsx (EJOUR)\n",
      "     -  ../data/llm-dump/misc/JFULL.xlsx (JFULL)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 102/6051 [00:00<00:05, 1013.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "syntax error in line 7: '}' expected"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 301/6051 [00:00<00:06, 921.51it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 394/6051 [00:00<00:06, 919.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "syntax error in line 6: premature end of file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 487/6051 [00:00<00:06, 902.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "syntax error in line 7: premature end of file\n",
      "syntax error in line 1: a valid name expected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 578/6051 [00:00<00:06, 807.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "syntax error in line 1: a valid name expected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 930/6051 [00:01<00:06, 835.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "syntax error in line 1: '(' or '{' expected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 1186/6051 [00:01<00:05, 840.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "syntax error in line 1: a valid name expected\n",
      "syntax error in line 2: '=' expected\n",
      "syntax error in line 4: '}' expected\n",
      "syntax error in line 4: '}' expected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1536/6051 [00:01<00:05, 853.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "syntax error in line 5: '}' expected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 1708/6051 [00:01<00:05, 845.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "syntax error in line 5: '}' expected\n",
      "Too many commas in 'Ostfriesischen Landschaft in Verb. mit den Heimatvereinen, der Industrie- und Handelskammer für Ostfriesland und Papenburg, der Handwerkskammer Aurich, dem Landesverkehrsverband Ostfriesland und dem Landwirtschaftlichen Hauptverein für Ostfriesland'\n",
      "syntax error in line 6: premature end of file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1979/6051 [00:02<00:04, 880.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entry with key JaarverslagCoehoorn has a duplicate issn field\n",
      "syntax error in line 1: a valid name expected\n",
      "syntax error in line 11: '=' expected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 2362/6051 [00:02<00:03, 934.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "syntax error in line 8: premature end of file\n",
      "syntax error in line 5: '}' expected\n",
      "syntax error in line 1: '(' or '{' expected\n",
      "syntax error in line 4: '}' expected\n",
      "syntax error in line 5: '}' expected\n",
      "syntax error in line 5: '}' expected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 2681/6051 [00:03<00:03, 1020.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "syntax error in line 5: '}' expected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 2904/6051 [00:03<00:02, 1064.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "syntax error in line 5: '}' expected\n",
      "syntax error in line 6: '=' expected\n",
      "syntax error in line 5: '}' expected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▎    | 3242/6051 [00:03<00:02, 1101.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "syntax error in line 1: a valid name expected\n",
      "syntax error in line 7: premature end of file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 3474/6051 [00:03<00:02, 1126.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "syntax error in line 5: '}' expected\n",
      "Too many commas in 'historische Kommission f{\\\\\"u}r Hannover, Oldenburg, Braunschweig, Schaumburg-Lippe und Bremen'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 3811/6051 [00:04<00:02, 1096.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "syntax error in line 1: ')' expected\n",
      "Too many commas in 'Wilken Engelbrecht, Judit Gera, Marta Kantor Farago, Jelica Novakovic, Jan Pekelder, Jana Raksanyiova'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 4250/6051 [00:04<00:01, 1063.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "syntax error in line 1: a valid name expected\n",
      "Too many commas in 'Centrale Vereniging voor Openbare Bibliotheken, Centrum voor Literatuuronderzoekers, Nederlands Instituut voor Informatie, Documentatie en Registratuur, Nederlandse Vereniging van Bedrijfsarchivarissen, Nederlandse Vereniging van Bibliothecarissen'\n",
      "syntax error in line 1: a valid name expected\n",
      "syntax error in line 4: '}' expected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 4478/6051 [00:04<00:01, 1085.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "syntax error in line 8: '}' expected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 4808/6051 [00:04<00:01, 1008.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "syntax error in line 16: premature end of file\n",
      "syntax error in line 1: a valid name expected\n",
      "syntax error in line 1: a valid name expected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 5313/6051 [00:05<00:00, 979.40it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Too many commas in 'Bureau voor Muziekauteursrecht, BUMA, Stichting tot Exploitatie van Mechanische Reproductierechten der Auteurs, STEMRA en Stichting SEBA tot Exploitatie van Auteursrechten'\n",
      "syntax error in line 5: '}' expected\n",
      "syntax error in line 5: '}' expected\n",
      "syntax error in line 5: '}' expected\n",
      "syntax error in line 12: '=' expected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 5607/6051 [00:05<00:00, 943.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "syntax error in line 5: '}' expected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 5806/6051 [00:06<00:00, 968.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "syntax error in line 1: entry key expected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6051/6051 [00:06<00:00, 968.70it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status\n",
      "success    6003\n",
      "failure      48\n",
      "Name: count, dtype: int64\n",
      "     -  ../data/llm-dump/misc/JOUR.xlsx (JOUR)\n",
      "     -  ../data/llm-dump/misc/WEB.xlsx (WEB)\n"
     ]
    }
   ],
   "source": [
    "llm_path = '../data/llm-dump'\n",
    "\n",
    "new_jtitles = Counter()\n",
    "\n",
    "for decade_folder in sorted(glob.glob(f'{llm_path}/*')):\n",
    "    #if '1990s' not in decade_folder:\n",
    "    #        continue\n",
    "    print(':::', decade_folder, ':::')\n",
    "\n",
    "    for spreadsheet_path in sorted(glob.glob(f'{decade_folder}/*.xlsx')):\n",
    "        df = pd.read_excel(spreadsheet_path, header=0, engine='openpyxl')\n",
    "        #n = 5000\n",
    "        #if len(df) > n:\n",
    "        #    df = df.sample(n)\n",
    "\n",
    "        if 'bibtex' not in df.columns:\n",
    "            continue\n",
    "    \n",
    "        ptype = os.path.basename(spreadsheet_path).replace('.xlsx', '')\n",
    "        print('     - ', spreadsheet_path, f'({ptype})')\n",
    "\n",
    "        #if ptype not in ('BOOK', 'JOUR', 'CHAP'):\n",
    "        if ptype != 'JFULL':\n",
    "            continue\n",
    "        \n",
    "        # parse the RIS (stored as JSON strings in the spreadsheet)\n",
    "        df['RIS'] = df['RIS'].apply(json.loads)\n",
    "\n",
    "        # clean (and deduplicate the bibtex returned by the LLM)\n",
    "        cleaned = []\n",
    "        for bt in df['bibtex']:\n",
    "            if isinstance(bt, str):\n",
    "                cleaned.append(clean_bibtex(bt))\n",
    "            else:\n",
    "                cleaned.append('')\n",
    "        df['bibtex-clean'] = cleaned\n",
    "\n",
    "        # Update the available RIS entries with newly structure info,\n",
    "        # returned by the LLM (and keep tracked of whether or not that is successful):\n",
    "        updated_ris, status = [], []\n",
    "        for ris, bibtex_str in tqdm(list(zip(df['RIS'], df['bibtex-clean']))):\n",
    "            if isinstance(bibtex_str, str):\n",
    "                try:\n",
    "                    #print(bibtex_parse)\n",
    "                    bibtex_parse = parse_string(bibtex_str, 'bibtex')\n",
    "                    single_key = list(bibtex_parse.entries.keys())[0]\n",
    "                    updated = map_entry[ptype](ris.copy(), bibtex_parse.entries[single_key])\n",
    "\n",
    "                    # keep track of new journal titles which lack a normalized variant,\n",
    "                    # (unless the difference is only in capitalization):\n",
    "                    if ptype == 'JOUR' and 'journal_name' in updated and updated['journal_name'] not in existing_jtitles:\n",
    "                        try:\n",
    "                            updated['journal_name'] = lower2jtitles[updated['journal_name'].lower()]\n",
    "                        except KeyError:\n",
    "                            new_jtitles[updated['journal_name']] += 1\n",
    "                    \n",
    "                    updated['label'] = 'success'\n",
    "                    updated_ris.append(updated)\n",
    "                    status.append('success')\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    ris['label'] = f'failure ({str(e)})'\n",
    "                    updated_ris.append(ris)\n",
    "                    status.append('failure')\n",
    "            else:\n",
    "                ris['label'] = 'failure'\n",
    "                updated_ris.append(ris)\n",
    "                status.append('failure')\n",
    "\n",
    "        # store the newly merged information as a JSON string that holds a RIS entry:\n",
    "        df['consolidated'] = [json.dumps(r, indent=2, ensure_ascii=False) for r in updated_ris]\n",
    "        df['status'] = status\n",
    "\n",
    "        # re-encode the original RIS entry as a JSON string in the original column:\n",
    "        df['RIS'] = [json.dumps(d, indent=2, ensure_ascii=False) for d in df['RIS']]\n",
    "\n",
    "        # remove the cleaned bibtex string:\n",
    "        del df['bibtex-clean']\n",
    "\n",
    "        # output new spreadsheet:\n",
    "        df.to_excel(spreadsheet_path, index=False, header=True)\n",
    "\n",
    "        # output updated RIS file:\n",
    "        with open(f'{decade_folder}/{ptype}_consolidated.ris', 'w') as bibliography_file:\n",
    "            rispy.dump(updated_ris, bibliography_file)\n",
    "\n",
    "        # show the failure statistics:\n",
    "        print(df['status'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d759fd3",
   "metadata": {},
   "source": [
    "Extract journal titles for which we don't have a normalization yet and map them provionally to the closest available normalized title (using the Levenshtein distance):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71a03b77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw title</th>\n",
       "      <th>count</th>\n",
       "      <th>normalized</th>\n",
       "      <th>issn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [raw title, count, normalized, issn]\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mappings = []\n",
    "for nj, cnt in new_jtitles.items():\n",
    "    distances = np.array([lev.distance(nj, oj) for oj in jtitle['normalized']])\n",
    "    mappings.append([nj, cnt] + list(jtitle.iloc[np.argmin(distances)][['normalized', 'issn']]))\n",
    "\n",
    "mappings = pd.DataFrame(mappings, columns=['raw title', 'count', 'normalized', 'issn'])\n",
    "mappings = mappings.sort_values('count', ascending=False)\n",
    "mappings.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61476c0",
   "metadata": {},
   "source": [
    "We save this spreadsheet for manual correction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1316bcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings.to_excel('../data/journal_titles_2ndBatch.xlsx', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe12a9ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.11",
   "language": "python",
   "name": "py3.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
